{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3dQ_iX_CxJOV"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQpHkt0ipk76Jyk2l9SqRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarlHajal/EE-554-ASR/blob/main/EE_554_Whisper_ASR_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EE-554 Whisper ASR Exercise\n",
        "\n",
        "## Introduction\n",
        "In this exercise, you will work with OpenAI's open-source Whisper speech recognition model to explore the capabilities and limitations of modern Automatic Speech Recognition (ASR) technology.\n",
        "\n",
        "You will test the model across various scenarios, evaluate its performance in each case, and analyze its strengths and weaknesses. By the end of the exercise, you will gain insights into the current state of ASR, identify areas where Whisper struggles, and consider potential improvements for future models."
      ],
      "metadata": {
        "id": "yXaKcIMHut25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Install Requirements"
      ],
      "metadata": {
        "id": "AH_dtrDjv8SJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAZ_6UbVumGf"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install ipywebrtc\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "from ipywebrtc import AudioRecorder, CameraStream\n",
        "from IPython.display import Audio, display, Markdown\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Download audio files"
      ],
      "metadata": {
        "id": "q0XAxNQEurWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KarlHajal/EE-554-ASR/"
      ],
      "metadata": {
        "id": "gKrGPvgBwT1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Transcribe Audio Files\n",
        "\n",
        "In this step, we will transcribe both typical and atypical speech recordings and analyze the model's performance.\n",
        "\n",
        "First, please listen to the recordings.\n",
        "\n"
      ],
      "metadata": {
        "id": "3dQ_iX_CxJOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(\"**Typical Speech:**\"))\n",
        "display(Markdown(\"Transcript: She then rose, humming the air to which she was presently going to dance.\"))\n",
        "display(Audio(\"/content/EE-554-ASR/typical.wav\", autoplay=False))\n",
        "display(Markdown(\"**Atypical Speech 1:**\"))\n",
        "display(Markdown(\"Transcript: He slowly takes a short walk in the open air each day.\"))\n",
        "display(Audio(\"/content/EE-554-ASR/atypical_1.wav\", autoplay=False))\n",
        "display(Markdown(\"**Atypical Speech 2:**\"))\n",
        "display(Markdown(\"Transcript: Peer.\"))\n",
        "display(Audio(\"/content/EE-554-ASR/atypical_2.wav\", autoplay=False))"
      ],
      "metadata": {
        "id": "OyKJqWtjvVmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Typical Speech:\n",
        "We will start by transcribing a typical speech recording.\n",
        "\n",
        "The ground truth transcript for that recording is:\n",
        "\n",
        "\n",
        "\"She then rose, humming the air to which she was presently going to dance.\""
      ],
      "metadata": {
        "id": "Ixvc__L_0YT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Typical Speech Recording\n",
        "!whisper \"/content/EE-554-ASR/typical.wav\" --model base --language English"
      ],
      "metadata": {
        "id": "ilNFxRSyxN_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Atypical Speech:\n",
        "\n",
        "We will now transcribe atypical speech recordings.\n",
        "\n",
        "The ground truth transcripts for the recordings are:\n",
        "\n",
        "atypical_1: \"He slowly takes a short walk in the open air each day.\"\n",
        "\n",
        "atypical_2: \"Peer.\""
      ],
      "metadata": {
        "id": "2saCzNPB00E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Atypical Speech Recording\n",
        "!whisper \"/content/EE-554-ASR/atypical_1.wav\" --model base --language English\n",
        "!whisper \"/content/EE-554-ASR/atypical_2.wav\" --model base --language English"
      ],
      "metadata": {
        "id": "sLoDBXRYxyOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis Questions\n",
        "\n",
        "* What did Whisper output for each speech sample?\n",
        "* Estimate the Word Error Rate for each transcription\n",
        "* How did the model's performance differ between typical and atypical speech?\n",
        "* Please comment on any surprising results you might have observed (Run the cell several times, did the model hallucinate in any of these tests?)"
      ],
      "metadata": {
        "id": "oRQxytnT19fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Record and Transcribe your own audio files\n",
        "\n",
        "In this step, you will record your voice using the tool below, then transcribe each recording to analyze the model's transcription performance.\n",
        "\n",
        "1. **Quiet Environment**: Start by recording yourself in a quiet environment, reading the following sentence: \"The quick red fox jumped over the lazy brown dog.\"\n",
        "\n",
        "2. **Noisy Environment**: Record the same sentence again, this time in a noisy environment. (e.g. introduce background noise such as music or ambient sounds from your phone).\n",
        "\n",
        "3. **Voice Modulation**: Record the sentence in a quiet environment again, but this time modulate your voice in various ways (e.g., change your pitch, speed, or tone) to see if you can \"fool\" the model into producing incorrect transcriptions.\n",
        "\n",
        "Make sure to grant the browser access to your microphone when prompted."
      ],
      "metadata": {
        "id": "U66vXI9T5AoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "camera = CameraStream(constraints={'audio': True,'video':False})\n",
        "recorder = AudioRecorder(stream=camera)\n",
        "recorder"
      ],
      "metadata": {
        "id": "CqtVt5hg28Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('my_recording.webm', 'wb') as f:\n",
        "    f.write(recorder.audio.value)\n",
        "!ffmpeg -i my_recording.webm -ac 1 -f wav my_recording.wav -y -hide_banner -loglevel panic\n",
        "!whisper \"/content/my_recording.wav\" --model base --language English"
      ],
      "metadata": {
        "id": "_MhAxKf85TsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis Questions\n",
        "* How did the model perform in each scenario? Please report the different outputs observed, and describe any differences in transcription accuracy.\n",
        "* Estimate the Word Error Rate for each recording.\n",
        "* Which types of voice changes were most effective in causing the model to produce inaccurate transcriptions?\n",
        "* Based on your observations, where does Whisper struggle and in what areas could it benefit from further improvement?"
      ],
      "metadata": {
        "id": "6C-xblEm85mp"
      }
    }
  ]
}